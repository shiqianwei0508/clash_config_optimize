#!/usr/bin/env python3
import argparse
# import os
from ruamel.yaml import YAML
from ruamel.yaml.scalarstring import DoubleQuotedScalarString
from ruamel.yaml.comments import CommentedMap
from collections import OrderedDict
import glob

# âœ… åˆ†ç»„å…³é”®è¯é…ç½®
group_keywords = {
    "ğŸ‡­ğŸ‡° é¦™æ¸¯": ["HK", "Hong Kong", "HKG", "é¦™æ¸¯"],
    "ğŸ‡¯ğŸ‡µ æ—¥æœ¬": ["JP", "Japan", "Tokyo", "æ—¥æœ¬"],
    "ğŸ‡°ğŸ‡· éŸ©å›½": ["KR", "Korea", "éŸ©å›½"],
    "ğŸ‡ºğŸ‡¸ ç¾å›½": ["US", "United States", "ç¾å›½", "ç¾åœ‹", "CA", "Canada", "åŠ æ‹¿å¤§"],
    "ğŸ‡¸ğŸ‡¬ æ–°åŠ å¡": ["SG", "Singapore", "æ–°åŠ å¡"],
    "ğŸ‡¨ğŸ‡³ ä¸­å›½": ["CN", "China", "ä¸­å›½"],
    "ğŸ‡ªğŸ‡º æ¬§æ´²": ["EU", "Europe", "æ¬§æ´²", "DE", "GB", "FR"],
    "ğŸš€ TGä»£ç†": ["t.me", "TG", "Telegram", "tg"],
    "ğŸ“¦ Other": ["Other"],
    "ğŸ§ª å…¶å®ƒ": []
}

yaml = YAML()
yaml.preserve_quotes = True
yaml.indent(sequence=4, offset=2)


def load_yaml(path):
    with open(path, 'r', encoding='utf-8') as f:
        return yaml.load(f)


def save_yaml(data, path):
    with open(path, 'w', encoding='utf-8') as f:
        yaml.dump(data, f)


def match_keywords(name, keywords):
    return any(k.lower() in name.lower() for k in keywords)


def group_proxy_names(proxies, keyword_config):
    groups = {key: [] for key in keyword_config.keys()}
    for proxy in proxies:
        name = proxy.get("name", "")
        matched = False
        for group, keywords in keyword_config.items():
            if match_keywords(name, keywords):
                groups[group].append(name)
                matched = True
                break
        if not matched:
            groups["ğŸ§ª å…¶å®ƒ"].append(name)
    return groups


def build_proxy_groups(groups):
    proxy_groups = []

    # åˆ†ç»„é€‰æ‹©å…¥å£
    proxies_for_entry = [DoubleQuotedScalarString("â™»ï¸ è‡ªåŠ¨é€‰æ‹©")]

    for group_name, proxy_names in groups.items():
        if proxy_names:
            proxies_for_entry.append(DoubleQuotedScalarString(group_name))  # url-test åˆ†ç»„
            proxies_for_entry.append(DoubleQuotedScalarString(f"{group_name}ğŸŒ€"))  # load-balance åˆ†ç»„

    proxy_groups.append({
        "name": "ğŸš€ èŠ‚ç‚¹é€‰æ‹©",
        "type": "select",
        "proxies": proxies_for_entry
    })

    # è‡ªåŠ¨é€‰æ‹©åˆ†ç»„
    all_proxy_names = [name for proxy_list in groups.values() for name in proxy_list]
    proxy_groups.append({
        "name": "â™»ï¸ è‡ªåŠ¨é€‰æ‹©",
        "type": "url-test",
        "url": "http://edge.microsoft.com/captiveportal/generate_204",
        "interval": 300,
        "tolerance": 50,
        "proxies": [DoubleQuotedScalarString(name) for name in all_proxy_names]
    })

    # ğŸŒ åœ°åŸŸåˆ†ç»„ + ğŸŒ å‡è¡¡åˆ†ç»„
    for group_name, proxy_names in groups.items():
        if proxy_names:
            proxies = [DoubleQuotedScalarString(name) for name in proxy_names]
            # url-test åˆ†ç»„
            proxy_groups.append({
                "name": f"{group_name}",
                "type": "url-test",
                "url": "http://edge.microsoft.com/captiveportal/generate_204",
                "interval": 300,
                "tolerance": 50,
                "proxies": proxies
            })
            # load-balance åˆ†ç»„ï¼ˆåå­—åŠ åç¼€ï¼‰
            proxy_groups.append({
                "name": f"{group_name}ğŸŒ€",
                "type": "load-balance",
                "strategy": "round-robin",
                "proxies": proxies
            })

    # æœåŠ¡å…¥å£åˆ†ç»„
    services = ["ğŸŒ å›½å¤–åª’ä½“", "â“‚ï¸ å¾®è½¯æœåŠ¡", "ğŸ è‹¹æœæœåŠ¡", "ğŸ“² ç”µæŠ¥ä¿¡æ¯"]

    full_refs = [DoubleQuotedScalarString("ğŸš€ èŠ‚ç‚¹é€‰æ‹©")]
    for group_name, proxy_names in groups.items():
        if proxy_names:
            full_refs.append(DoubleQuotedScalarString(group_name))  # url-test åˆ†ç»„
            full_refs.append(DoubleQuotedScalarString(f"{group_name}ğŸŒ€"))  # load-balance åˆ†ç»„

    for service in services:
        proxy_groups.append({
            "name": service,
            "type": "select",
            "proxies": full_refs
        })

    # å›ºå®šåˆ†ç»„
    fixed = [
        ("ğŸ¯ å…¨çƒç›´è¿", ["DIRECT", "ğŸš€ èŠ‚ç‚¹é€‰æ‹©", "â™»ï¸ è‡ªåŠ¨é€‰æ‹©"]),
        ("ğŸ›‘ å…¨çƒæ‹¦æˆª", ["REJECT", "DIRECT"]),
        ("ğŸƒ åº”ç”¨å‡€åŒ–", ["REJECT", "DIRECT"]),
        ("ğŸŸ æ¼ç½‘ä¹‹é±¼", ["ğŸš€ èŠ‚ç‚¹é€‰æ‹©", "ğŸ¯ å…¨çƒç›´è¿", "â™»ï¸ è‡ªåŠ¨é€‰æ‹©"])
    ]
    for name, proxies in fixed:
        proxy_groups.append({
            "name": name,
            "type": "select",
            "proxies": [DoubleQuotedScalarString(p) for p in proxies]
        })

    return proxy_groups


def override_base_config(config):
    config.pop("mixed-port", None)
    ordered_fields = CommentedMap()
    ordered_fields["port"] = 7890
    ordered_fields["socks-port"] = 7891
    ordered_fields["allow-lan"] = True

    for key in list(ordered_fields.keys()):
        if key in config:
            config.pop(key)

    for k, v in reversed(list(ordered_fields.items())):
        config.insert(0, k, v)

    print("ğŸ”§ å·²é‡æ’åŸºç¡€å­—æ®µï¼šport â†’ socks-port â†’ allow-lanï¼Œç§»é™¤ mixed-port")


def merge_proxies(config_paths):
    all_configs = [load_yaml(p) for p in config_paths]
    proxy_dict = OrderedDict()
    for conf in all_configs:
        for proxy in conf.get("proxies", []):
            name = proxy.get("name")
            if name and name not in proxy_dict:
                proxy_dict[name] = proxy
    base = all_configs[0].copy()
    base["proxies"] = list(proxy_dict.values())
    return base


def dedupe_proxies(proxies, output_file="duplicates.txt"):
    seen = set()
    deduped = []
    duplicates = []

    for proxy in proxies:
        proxy_type = proxy.get("type")
        port = proxy.get("port")

        # ä½¿ç”¨ä¸åŒçš„å»é‡é”®
        if proxy_type == "trojan":
            key = (proxy.get("sni"), port, proxy_type)
        else:
            key = (proxy.get("server"), port, proxy_type)

        if key not in seen:
            seen.add(key)
            deduped.append(proxy)
        else:
            duplicates.append(proxy)

    # å†™å…¥é‡å¤é¡¹åˆ°æ–‡ä»¶
    if duplicates:
        with open(output_file, "w", encoding="utf-8") as f:
            f.write(f"ğŸ” å…±åˆå¹¶é‡å¤èŠ‚ç‚¹ï¼š{len(duplicates)} ä¸ª\n")
            f.write("ğŸ“‹ é‡å¤èŠ‚ç‚¹å¦‚ä¸‹ï¼š\n")
            for dup in duplicates:
                f.write(f"  - {dup}\n")

    return deduped


def main():
    parser = argparse.ArgumentParser(description="ğŸ› ï¸ Clash YAML å¤šæ–‡ä»¶åˆå¹¶ä¼˜åŒ–å·¥å…·")
    parser.add_argument("--clashconfig", nargs="+", required=True, help="å¤šä¸ªåŸå§‹é…ç½®è·¯å¾„")
    parser.add_argument("--newconfig", default="config.yaml", help="è¾“å‡ºé…ç½®è·¯å¾„ï¼ˆé»˜è®¤ï¼šconfig.yamlï¼‰")
    args = parser.parse_args()

    # clashconfig å‚æ•°å€¼å¤„ç†
    raw_paths = args.clashconfig
    expanded_paths = []

    for pattern in raw_paths:
        matched = glob.glob(pattern)
        if not matched:
            print(f"âŒ æœªåŒ¹é…åˆ°æ–‡ä»¶ï¼š{pattern}")
            return
        expanded_paths.extend(matched)

    config = merge_proxies(expanded_paths)

    # å¤„ç† proxies å­—æ®µ
    proxies = dedupe_proxies(config.get("proxies", []))
    config["proxies"] = proxies

    if not proxies:
        print("âš ï¸ proxies å­—æ®µä¸ºç©º")
        return

    # è¦†ç›–åŸºç¡€é…ç½®
    override_base_config(config)

    grouped = group_proxy_names(proxies, group_keywords)
    config["proxy-groups"] = build_proxy_groups(grouped)

    # newconfig å‚æ•°å€¼å¤„ç†
    save_yaml(config, args.newconfig)

    print(f"\nâœ… é…ç½®ç”ŸæˆæˆåŠŸï¼š{args.newconfig}")
    print(f"ğŸ“¦ åˆ†ç»„æ•°ï¼š{len(config['proxy-groups'])}")
    for g in config["proxy-groups"]:
        print(f"   - {g['name']}: {len(g.get('proxies', []))} ä¸ªèŠ‚ç‚¹")


if __name__ == "__main__":
    main()
